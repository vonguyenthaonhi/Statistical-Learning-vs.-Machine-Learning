**Statistical Learning vs. Machine Learning**

**BACKGROUND** This paper explores the crucial task of variable selection in model building, comparing methods between Statistical Learning and Machine Learning. By assessing different scenarios and criteria, it aims to identify the most effective approach.

**AIM** Through theoretical analysis and empirical studies, the paper provides insights into the strengths and weaknesses of various methods, helping researchers choose the best approach for their modelling needs.

**METHOD** 
- Firstly, we employ various DGPs to simulate different scenarios of data types, each designed to represent distinct hypotheses. These scenarios include linear independence, multicollinearity, multicollinearity with outliers, linear dependence, linear dependence with one break, and linear dependence with numerous breaks. For each DGP, we generate datasets consisting of 500 observations and 50 predictors, with adjustments made to introduce specific characteristics such as correlations, breaks, and outliers.
- Secondly, we employ statistical techniques, specifically the GLMSELECT procedure in SAS, to conduct variable selection using various criteria and stopping rules like AICc, BIC, adjusted R-squared, and Mallow’s Cp. These methods produce models with effects chosen differently, allowing us to assess their performance across different scenarios.
- To evaluate each method, we use metrics based on the likelihood of well-fitting, overfitting, underfitting, and failure, determined by comparing the final selected variables with the true set. Through Monte Carlo simulations with 1000 iterations per Data Generation Process (DGP), we gain comprehensive insights into the effectiveness of each variable selection approach and criterion in capturing the underlying data patterns accurately.
  
**RESULTS** Based on the comparison between Statistical Learning and Machine Learning methods across various Data Generating Processes (DGPs), several important findings emerge. When using the same criterion for choose and stop option, Stepwise is the most useful method. Meanwhile, when the criterion for choose and stop option are not the same, LAR and LASSO surpass Stepwise. Concerning the selection criteria, Statistical Learning methods generally perform better with criteria such as Adjusted R-squared and Mallows' Cp, while Machine Learning methods excel with criteria like K-fold cross-validation and Leave-One-Out cross-validation. However, Cp is a sensitive criterion that often yields an abnormally high probability of well-fitting, particularly when disturbance exists, for example in all DGPs except for the benchmark DGP1. Furthermore, empirical application results suggest that changes in coefficients of 	β and residuals significantly impact the performance of methods. For instance, reducing the residuals tends to increase the probability of well-fitting across methods, while increasing $\beta$ may not always lead to improved fitting probabilities.

**CONCLUSION** The analysis of various model selection criteria across different DGPs reveal important insights into the performance of statistical and Machine Learning methods. Across multiple scenarios, the LAR and LASSO method with SBC as choose option and Leave-one-out cross-validation as stop option consistently emerges as a robust and efficient approach, demonstrating competitive well-fitting rates compared to alternative methods. Moreover, adjustments in model coefficients and residuals underscore the sensitivity of method performance to underlying data characteristics, emphasizing the importance of thoughtful model selection in empirical applications. Our study's constraints involve rigid adherence to multivariate normal distributions for Data Generating Processes (DGPs), oversight in examining combined disturbances, and a lack of individual variable probabilities. Random parameter variation underscores the necessity for systematic Signal-to-Noise Ratio (SNR) exploration. Time limitations prevented empirical applications on real-life data, indicating a need for future investigation in this area.

**KEYWORDS** Statistical Learning · Machine Learning · Forward/Backward/Stepwise selection· Forward Stagewise/LAR/LASSO/Elastic net · AICc/BIC/SBC/Cp · K-fold/Leave-one-out cross-validation · Monte Carlo simulation
